{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b16d28-d866-4ca9-afad-2cc226214317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5660e856-c812-446a-b9d9-c16653d06211",
   "metadata": {},
   "source": [
    "#### Question 1: What's the (MLflow) version that you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bc9822-6c4a-4800-ab81-bdd13439c2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6754f7aa-69d6-45c1-8d28-d6bb57adff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw/green_tripdata_2023-01.parquet already exists.\n",
      "data/raw/green_tripdata_2023-02.parquet already exists.\n",
      "data/raw/green_tripdata_2023-03.parquet already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data/raw/\n",
    "\n",
    "# List of URLs to download\n",
    "urls = [\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-01.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-03.parquet\"\n",
    "]\n",
    "\n",
    "# Download each file to the specified directory if it doesn't already exist\n",
    "for url in urls:\n",
    "    filename = os.path.join(\"data/raw/\", os.path.basename(url))\n",
    "    if not os.path.exists(filename):\n",
    "        !wget -P data/raw/ {url}\n",
    "    else:\n",
    "        print(f\"{filename} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b30c809-6640-4f8a-9b82-c15f5826d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python homework_scripts/original/preprocess_data.py --raw_data_path ./data/raw --dest_path ./data/preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb92de-63bc-4997-b2d1-21b45532890d",
   "metadata": {},
   "source": [
    "#### Question 2: How many files were saved to OUTPUT_FOLDER?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065e01b8-238d-4191-a683-6f89d321fbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_and_dirs = os.listdir('./data/preprocessed')\n",
    "    \n",
    "files = [f for f in files_and_dirs if os.path.isfile(os.path.join('./data/preprocessed', f))]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dba2d28-5bfc-4d5d-b964-5fe6afc27038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/05/23 23:06:54 INFO mlflow.tracking.fluent: Experiment with name 'Homework 2' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "!python homework_scripts/edited/train.py --data_path ./data/preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d1736d6-918f-4058-b5b1-9ebc44fa7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d7d615-534e-40bf-91b1-0bbf7628177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = client.get_experiment_by_name(name=\"Homework 2\")\n",
    "\n",
    "run = client.search_runs(experiment_ids=[experiment.experiment_id])[0]\n",
    "#pprint(run.to_dictionary(), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3498154-5377-4490-84ed-d2b74abbdbf8",
   "metadata": {},
   "source": [
    "#### Question 3: What is the value of the min_samples_split parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19f81afe-489a-4ecf-acec-943acecbffbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.data.params['min_samples_split']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d0301-9749-4a36-88b2-62d1b5d94ede",
   "metadata": {},
   "source": [
    "#### Question 4: In addition to backend-store-uri, what else do you need to pass to properly configure the server?\n",
    "\n",
    "1. default-artifact-root\n",
    "1. serve-artifacts\n",
    "1. artifacts-only\n",
    "1. artifacts-destination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8a3cf-a5b1-4d20-80f9-8e8da046a7d6",
   "metadata": {},
   "source": [
    "**Answer**: to properly configure and launch the MLflow tracking server with a SQLite backend and a specified folder for the artifact store, you need to pass the following parameters in addition to `backend-store-uri`:\n",
    "\n",
    "    mlflow server \\\n",
    "        --backend-store-uri sqlite:///mlflow.db \\\n",
    "        --default-artifact-root ./artifacts \\\n",
    "        --host 0.0.0.0\n",
    "\n",
    "- **`--backend-store-uri`** sqlite:///mlflow.db specifies the SQLite database for the backend store.\n",
    "- **`--default-artifact-root`** ./artifacts specifies the folder called artifacts for the artifact store.\n",
    "- **`--host 0.0.0.0`** allows access from any IP address.\n",
    "\n",
    "If you do not set these up explicitly, MLflow uses default behaviors. You can inspect the default URIs using the following methods:\n",
    "\n",
    "- Run `mlflow.get_artifact_uri()` to get the default artifact URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e02733-f164-4a9b-9f45-cd8332334919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/ubuntu/datatalks-mlops-zoomcamp/02-exp-tracking/mlruns'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1daae-0cde-435d-96de-98b610a05e18",
   "metadata": {},
   "source": [
    "- Run `mlflow.get_tracking_uri()` to get the default tracking URI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca7f0c5-bfcd-4ca2-bfd9-a0c8538a5719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/ubuntu/datatalks-mlops-zoomcamp/02-exp-tracking/mlruns/0/1e1d3a35043440e3b9fe78d2687c4562/artifacts'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_artifact_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e159964-197a-450a-928c-2f0de088d4df",
   "metadata": {},
   "source": [
    "- Additionally, you can inspect the artifact URI from a `mlflow.entities.run.Run` object with `run.info.artifact_uri`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a6b823-ec0a-4177-9969-3c5c2e4c598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/ubuntu/datatalks-mlops-zoomcamp/02-exp-tracking/mlruns/393138072735723419/22026f469fa84e87b2dd8472159441a4/artifacts'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.info.artifact_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e89f88-d4e4-4449-9212-45b6b5399d4c",
   "metadata": {},
   "source": [
    "As you can see, if you don't set a `backend-store-uri`, MLflow uses the `./mlruns` directory by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4011cc87-8239-4be5-9769-e28630801892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/05/23 23:07:18 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-hyperopt' does not exist. Creating a new experiment.\n",
      "100%|██████████| 15/15 [02:03<00:00,  8.22s/trial, best loss: 5.335419588556921]\n"
     ]
    }
   ],
   "source": [
    "!python homework_scripts/edited/hpo.py --data_path ./data/preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26810e22-7f01-4133-b69f-af6ae7abf23d",
   "metadata": {},
   "source": [
    "The hyperopt script is already telling us the answer (5.335). However, let's find it out using mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b2879c-2df0-4390-98ba-24472751804b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "886471705322384834 - 20c1be0d37584bb3a58ae54a02ca2ceb - persistent-whale-928\n"
     ]
    }
   ],
   "source": [
    "experiment = mlflow.get_experiment_by_name('random-forest-hyperopt')\n",
    "metric_name = 'rmse'\n",
    "\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[f\"metrics.{metric_name} ASC\"],\n",
    "    max_results=15\n",
    ")\n",
    "\n",
    "best_run = runs.iloc[0]\n",
    "print(f\"{best_run['experiment_id']} - {best_run['run_id']} - {best_run['tags.mlflow.runName']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0e797-76d6-4efb-8b90-a5da2b2d5e03",
   "metadata": {},
   "source": [
    "#### Question 5: what's the best validation RMSE that you got?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72d67f3-9a4c-489a-aca7-de02d13098b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.335419588556921"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run['metrics.rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "258f4331-8368-4e72-b3fb-8c909d148e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/05/23 23:09:23 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-best-models' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "!python homework_scripts/edited/register_model.py --data_path ./data/preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "903e79f4-3709-48bd-b535-a598b6c41eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'aliases': [],\n",
      "  'creation_timestamp': 1716505820381,\n",
      "  'current_stage': 'None',\n",
      "  'description': None,\n",
      "  'last_updated_timestamp': 1716505820381,\n",
      "  'name': 'random-forest-reg-model',\n",
      "  'run_id': '05f10ac6db674545b7082d5508e8942c',\n",
      "  'run_link': None,\n",
      "  'source': 'mlruns/680284922997686276/05f10ac6db674545b7082d5508e8942c/artifacts/model',\n",
      "  'status': 'READY',\n",
      "  'status_message': None,\n",
      "  'tags': {},\n",
      "  'user_id': None,\n",
      "  'version': 1}\n"
     ]
    }
   ],
   "source": [
    "for mv in client.search_model_versions(\"name='random-forest-reg-model'\"):\n",
    "    pprint(dict(mv), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2ea62-6378-4974-8c88-341dbb95e970",
   "metadata": {},
   "source": [
    "#### Question 6: what is the test RMSE of the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb792d75-42c4-4be8-ae3d-fc4211fa8f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': 5.5941605655803635,\n",
       " 'val_rmse': 5.3633599989832135,\n",
       " 'training_mean_absolute_error': 3.323916924052877,\n",
       " 'training_root_mean_squared_error': 5.107146456952711,\n",
       " 'training_score': 0.6796805248104354,\n",
       " 'training_mean_squared_error': 26.08294493276463,\n",
       " 'training_r2_score': 0.6796805248104354}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.get_run('4e89e7da25c4497ea0f236945832b37c')\n",
    "run.data.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6071de1-180a-4a6a-ac45-906c15b8c550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
